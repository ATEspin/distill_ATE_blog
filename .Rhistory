create_theme(name = "theme")
library(distill)
create_theme(name = "theme")
install.packages("postcards")
postcards::create_postcard("about.Rmd")
postcards::create_postcard("about2.Rmd")
render_site()
distill::render_site()
library(rmarkdown)
render_site()
render_site()
render_site()
render_site()
render_site()
knitr::opts_chunk$set(echo = FALSE)
x
?htmltools::a
library(easyPubMed) #API connection with pubmed
library(tidyverse) #To facilitate some data wrangling
library(DT) # for table html formatting
library(htmltools)
## This creates a search that gets saved in NML servers with specific ids, that makes the query reusable without the need to search again.
my_entrez_id <- get_pubmed_ids('Abel Torres-Espin')
## This fetches the pubmed info for each paper returned as list of string character vector
track_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
## Creates an index of where the papers start in the track_txt string
paper_list_index<-c(which(track_txt==""),length(track_txt))
## Extract papers by list
paper_list<-list()
for(i in 1:(length(paper_list_index)-1)){
paper_list[[i]]<-track_txt[seq(paper_list_index[i],paper_list_index[i+1]-1)]
}
## List of PMIDs using the PMID tag
PMC_list<-track_txt[str_detect(track_txt, "^PMID- ")]
PMC_list<-unique(str_remove_all(PMC_list, '^PMID- '))
### build the dataframe
extract<-list()
for (p in 1:length(paper_list)){
i<-paper_list[[p]]
## Author names
author_names<-i[str_detect(i, "^AU ")]
author_names<-paste0(str_remove_all(author_names, "^AU  - "), collapse="; ")
## PMIDs
PMID<-i[str_detect(i, "^PMID- ")]
PMID<-str_remove_all(PMID, '^PMID- ')
## Date publication
date_p<-i[str_detect(i, "^DP ")]
date_p<-str_remove_all(date_p, '^DP  - ')
## year
year<-str_extract(date_p,"[[:digit:]]+")
## Title
title<-i[str_detect(i, "^TI ")]
title<-str_remove_all(title, '^TI  - ')
## Publication info
pub_info<-i[str_detect(i, "^SO ")]
pub_info<-str_remove_all(pub_info, '^SO  - ')
## DOI
lid<-i[str_detect(i, "^LID ")]
lid<-str_remove_all(lid, '^LID - ')
if (length(lid)>0){
if (str_detect(lid, "doi")){
lid<-str_remove_all(lid, ' .+')
lid<-paste0("https://doi.org/", lid)
}else{
lid<-NULL
}
}else{
lid<-NULL
}
## join all info in dataframe
extract[[p]]<-data.frame("Year" = ifelse(is_empty(year), "No year", year),
"Title" = ifelse(is_empty(title), "No title", title),
"Authors" = ifelse(is_empty(author_names),
"No names", author_names),
"Info" = ifelse(is_empty(pub_info), "No info", pub_info),
"PMID" = ifelse(is_empty(PMID), "No PMID", PMID),
"DOI" = ifelse(is_empty(lid), "No DOI", lid))
}
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(Year)
pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df, rownames = NULL)
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(desc(Year))
pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
datatable(pub_df, rownames = NULL)
x
year_list<-list()
years<-sort(unique(pub_df$Year), decreasing = T)
for (i in 1:length(years)){
year<-years[i]
temp_df<-pub_df[pub_df$Year==year,]
## papers per year
temp_tags<-apply(temp_df, 1, function(x){
list(
tags$h4(
(if (!is.na(x[5])) {
tags$a(href = x[6],x[2],target="_blank")
}else{
tags$a(x[2],target="_blank")
})),
tags$p(x[3],x[4])
)
})
year_list[[i]]<-
tags$div(class = year,
tags$h2(year),
temp_tags
)
}
x<-tags$div(class="top",
year_list)
x
# write.table(htmltools::renderTags(x)$html, file = "test.txt", quote = F, row.names = F)
year_list
year_list<-list()
years<-sort(unique(pub_df$Year), decreasing = T)
for (i in 1:length(years)){
year<-years[i]
temp_df<-pub_df[pub_df$Year==year,]
## papers per year
temp_tags<-apply(temp_df, 1, function(x){
list(
tags$h4(
(if (!is.na(x[5])) {
tags$a(href = x[6],x[2],target="_blank")
}else{
tags$a(x[2],target="_blank")
})),
tags$p(x[3],x[4])
)
})
# year_list[[i]]<-
#   tags$div(class = year,
tags$h2(year)
temp_tags
}
# x<-tags$div(class="top",
#            year_list)
#
# x
# write.table(htmltools::renderTags(x)$html, file = "test.txt", quote = F, row.names = F)
# year_list[[i]]<-
#   tags$div(class = year,
print(tags$h2(year))
print(temp_tags)
# year_list[[i]]<-
#   tags$div(class = year,
htmltools::renderTags(tags$h2(year))
htmltools::renderTags(temp_tags)
# year_list[[i]]<-
#   tags$div(class = year,
cat(tags$h2(year))
year_list<-list()
years<-sort(unique(pub_df$Year), decreasing = T)
for (i in 1:length(years)){
year<-years[i]
temp_df<-pub_df[pub_df$Year==year,]
## papers per year
temp_tags<-apply(temp_df, 1, function(x){
list(
tags$h4(
(if (!is.na(x[5])) {
tags$a(href = x[6],x[2],target="_blank")
}else{
tags$a(x[2],target="_blank")
})),
tags$p(x[3],x[4])
)
})
year_list[[tags$h2(year)]]<-temp_tags
}
year_list[[tags$h2(year)]]<-temp_tags
year_list<-list()
years<-sort(unique(pub_df$Year), decreasing = T)
for (i in 1:length(years)){
year<-years[i]
temp_df<-pub_df[pub_df$Year==year,]
## papers per year
temp_tags<-apply(temp_df, 1, function(x){
list(
tags$h4(
(if (!is.na(x[5])) {
tags$a(href = x[6],x[2],target="_blank")
}else{
tags$a(x[2],target="_blank")
})),
tags$p(x[3],x[4])
)
})
year_list[[i]]<-list(tags$h2(year),temp_tags)
}
x<-tags$div(class="top",
year_list)
x
# write.table(htmltools::renderTags(x)$html, file = "test.txt", quote = F, row.names = F)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df, rownames = NULL)
pub_df$Title<-tags$a(href = pub_df$Link,pub_df$Title,target="_blank")
tags$a(href = pub_df$Link,pub_df$Title,target="_blank")
pub_df$Link
##link
link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", PMID)
title<-tags$a(href = link,title,target="_blank")
title
pub_df<-pub_df%>%select(-DOI)
library(easyPubMed) #API connection with pubmed
library(tidyverse) #To facilitate some data wrangling
library(DT) # for table html formatting
library(htmltools)
## This creates a search that gets saved in NML servers with specific ids, that makes the query reusable without the need to search again.
my_entrez_id <- get_pubmed_ids('Abel Torres-Espin')
## This fetches the pubmed info for each paper returned as list of string character vector
track_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
## Creates an index of where the papers start in the track_txt string
paper_list_index<-c(which(track_txt==""),length(track_txt))
## Extract papers by list
paper_list<-list()
for(i in 1:(length(paper_list_index)-1)){
paper_list[[i]]<-track_txt[seq(paper_list_index[i],paper_list_index[i+1]-1)]
}
## List of PMIDs using the PMID tag
PMC_list<-track_txt[str_detect(track_txt, "^PMID- ")]
PMC_list<-unique(str_remove_all(PMC_list, '^PMID- '))
### build the dataframe
extract<-list()
for (p in 1:length(paper_list)){
i<-paper_list[[p]]
## Author names
author_names<-i[str_detect(i, "^AU ")]
author_names<-paste0(str_remove_all(author_names, "^AU  - "), collapse="; ")
## PMIDs
PMID<-i[str_detect(i, "^PMID- ")]
PMID<-str_remove_all(PMID, '^PMID- ')
## Date publication
date_p<-i[str_detect(i, "^DP ")]
date_p<-str_remove_all(date_p, '^DP  - ')
## year
year<-str_extract(date_p,"[[:digit:]]+")
## Title
title<-i[str_detect(i, "^TI ")]
title<-str_remove_all(title, '^TI  - ')
## Publication info
pub_info<-i[str_detect(i, "^SO ")]
pub_info<-str_remove_all(pub_info, '^SO  - ')
## DOI
lid<-i[str_detect(i, "^LID ")]
lid<-str_remove_all(lid, '^LID - ')
if (length(lid)>0){
if (str_detect(lid, "doi")){
lid<-str_remove_all(lid, ' .+')
lid<-paste0("https://doi.org/", lid)
}else{
lid<-NULL
}
}else{
lid<-NULL
}
##link
link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", PMID)
title<-tags$a(href = link,title,target="_blank")
## join all info in dataframe
extract[[p]]<-data.frame("Year" = ifelse(is_empty(year), "No year", year),
"Title" = ifelse(is_empty(title), "No title", title),
"Authors" = ifelse(is_empty(author_names),
"No names", author_names),
"Info" = ifelse(is_empty(pub_info), "No info", pub_info),
"PMID" = ifelse(is_empty(PMID), "No PMID", PMID),
"DOI" = ifelse(is_empty(lid), "No DOI", lid))
}
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(desc(Year))
# pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df, rownames = NULL, escape = 2,
options = list(
autoWidth = TRUE, columnDefs = list(list(width = '200px', targets = c(1, 3))))
)
View(pub_df)
title<-tags$a(href = link,title,target="_blank")
View(title)
title<-print(tags$a(href = link,title,target="_blank"))
print(tags$a(href = link,title,target="_blank"))
library(easyPubMed) #API connection with pubmed
library(tidyverse) #To facilitate some data wrangling
library(DT) # for table html formatting
library(htmltools)
## This creates a search that gets saved in NML servers with specific ids, that makes the query reusable without the need to search again.
my_entrez_id <- get_pubmed_ids('Abel Torres-Espin')
## This fetches the pubmed info for each paper returned as list of string character vector
track_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
## Creates an index of where the papers start in the track_txt string
paper_list_index<-c(which(track_txt==""),length(track_txt))
## Extract papers by list
paper_list<-list()
for(i in 1:(length(paper_list_index)-1)){
paper_list[[i]]<-track_txt[seq(paper_list_index[i],paper_list_index[i+1]-1)]
}
## List of PMIDs using the PMID tag
PMC_list<-track_txt[str_detect(track_txt, "^PMID- ")]
PMC_list<-unique(str_remove_all(PMC_list, '^PMID- '))
### build the dataframe
extract<-list()
for (p in 1:length(paper_list)){
i<-paper_list[[p]]
## Author names
author_names<-i[str_detect(i, "^AU ")]
author_names<-paste0(str_remove_all(author_names, "^AU  - "), collapse="; ")
## PMIDs
PMID<-i[str_detect(i, "^PMID- ")]
PMID<-str_remove_all(PMID, '^PMID- ')
## Date publication
date_p<-i[str_detect(i, "^DP ")]
date_p<-str_remove_all(date_p, '^DP  - ')
## year
year<-str_extract(date_p,"[[:digit:]]+")
## Title
title<-i[str_detect(i, "^TI ")]
title<-str_remove_all(title, '^TI  - ')
## Publication info
pub_info<-i[str_detect(i, "^SO ")]
pub_info<-str_remove_all(pub_info, '^SO  - ')
## DOI
lid<-i[str_detect(i, "^LID ")]
lid<-str_remove_all(lid, '^LID - ')
if (length(lid)>0){
if (str_detect(lid, "doi")){
lid<-str_remove_all(lid, ' .+')
lid<-paste0("https://doi.org/", lid)
}else{
lid<-NULL
}
}else{
lid<-NULL
}
##link
link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", PMID)
title<-print(tags$a(href = link,title,target="_blank"))
## join all info in dataframe
extract[[p]]<-data.frame("Year" = ifelse(is_empty(year), "No year", year),
"Title" = ifelse(is_empty(title), "No title", title),
"Authors" = ifelse(is_empty(author_names),
"No names", author_names),
"Info" = ifelse(is_empty(pub_info), "No info", pub_info),
"PMID" = ifelse(is_empty(PMID), "No PMID", PMID),
"DOI" = ifelse(is_empty(lid), "No DOI", lid))
}
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(desc(Year))
# pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
title<-htmltools::a(href = link,title,target="_blank")
title
View(title)
title<-htmltools::renderTags(tags$a(href = link,title,target="_blank"))
View(title)
library(easyPubMed) #API connection with pubmed
library(tidyverse) #To facilitate some data wrangling
library(DT) # for table html formatting
library(htmltools)
## This creates a search that gets saved in NML servers with specific ids, that makes the query reusable without the need to search again.
my_entrez_id <- get_pubmed_ids('Abel Torres-Espin')
## This fetches the pubmed info for each paper returned as list of string character vector
track_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
## Creates an index of where the papers start in the track_txt string
paper_list_index<-c(which(track_txt==""),length(track_txt))
## Extract papers by list
paper_list<-list()
for(i in 1:(length(paper_list_index)-1)){
paper_list[[i]]<-track_txt[seq(paper_list_index[i],paper_list_index[i+1]-1)]
}
## List of PMIDs using the PMID tag
PMC_list<-track_txt[str_detect(track_txt, "^PMID- ")]
PMC_list<-unique(str_remove_all(PMC_list, '^PMID- '))
### build the dataframe
extract<-list()
for (p in 1:length(paper_list)){
i<-paper_list[[p]]
## Author names
author_names<-i[str_detect(i, "^AU ")]
author_names<-paste0(str_remove_all(author_names, "^AU  - "), collapse="; ")
## PMIDs
PMID<-i[str_detect(i, "^PMID- ")]
PMID<-str_remove_all(PMID, '^PMID- ')
## Date publication
date_p<-i[str_detect(i, "^DP ")]
date_p<-str_remove_all(date_p, '^DP  - ')
## year
year<-str_extract(date_p,"[[:digit:]]+")
## Title
title<-i[str_detect(i, "^TI ")]
title<-str_remove_all(title, '^TI  - ')
## Publication info
pub_info<-i[str_detect(i, "^SO ")]
pub_info<-str_remove_all(pub_info, '^SO  - ')
## DOI
lid<-i[str_detect(i, "^LID ")]
lid<-str_remove_all(lid, '^LID - ')
if (length(lid)>0){
if (str_detect(lid, "doi")){
lid<-str_remove_all(lid, ' .+')
lid<-paste0("https://doi.org/", lid)
}else{
lid<-NULL
}
}else{
lid<-NULL
}
##link
link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", PMID)
title<-htmltools::renderTags(tags$a(href = link,title,target="_blank"))$html
## join all info in dataframe
extract[[p]]<-data.frame("Year" = ifelse(is_empty(year), "No year", year),
"Title" = ifelse(is_empty(title), "No title", title),
"Authors" = ifelse(is_empty(author_names),
"No names", author_names),
"Info" = ifelse(is_empty(pub_info), "No info", pub_info),
"PMID" = ifelse(is_empty(PMID), "No PMID", PMID),
"DOI" = ifelse(is_empty(lid), "No DOI", lid))
}
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(desc(Year))
# pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df, rownames = NULL, escape = 2,
options = list(
autoWidth = TRUE, columnDefs = list(list(width = '200px', targets = c(1, 3))))
)
