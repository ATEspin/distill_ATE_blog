create_theme(name = "theme")
library(distill)
create_theme(name = "theme")
install.packages("postcards")
postcards::create_postcard("about.Rmd")
postcards::create_postcard("about2.Rmd")
render_site()
distill::render_site()
library(rmarkdown)
render_site()
render_site()
render_site()
render_site()
render_site()
knitr::opts_chunk$set(echo = FALSE)
x
?htmltools::a
library(easyPubMed) #API connection with pubmed
library(tidyverse) #To facilitate some data wrangling
library(DT) # for table html formatting
library(htmltools)
## This creates a search that gets saved in NML servers with specific ids, that makes the query reusable without the need to search again.
my_entrez_id <- get_pubmed_ids('Abel Torres-Espin')
## This fetches the pubmed info for each paper returned as list of string character vector
track_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
## Creates an index of where the papers start in the track_txt string
paper_list_index<-c(which(track_txt==""),length(track_txt))
## Extract papers by list
paper_list<-list()
for(i in 1:(length(paper_list_index)-1)){
paper_list[[i]]<-track_txt[seq(paper_list_index[i],paper_list_index[i+1]-1)]
}
## List of PMIDs using the PMID tag
PMC_list<-track_txt[str_detect(track_txt, "^PMID- ")]
PMC_list<-unique(str_remove_all(PMC_list, '^PMID- '))
### build the dataframe
extract<-list()
for (p in 1:length(paper_list)){
i<-paper_list[[p]]
## Author names
author_names<-i[str_detect(i, "^AU ")]
author_names<-paste0(str_remove_all(author_names, "^AU  - "), collapse="; ")
## PMIDs
PMID<-i[str_detect(i, "^PMID- ")]
PMID<-str_remove_all(PMID, '^PMID- ')
## Date publication
date_p<-i[str_detect(i, "^DP ")]
date_p<-str_remove_all(date_p, '^DP  - ')
## year
year<-str_extract(date_p,"[[:digit:]]+")
## Title
title<-i[str_detect(i, "^TI ")]
title<-str_remove_all(title, '^TI  - ')
## Publication info
pub_info<-i[str_detect(i, "^SO ")]
pub_info<-str_remove_all(pub_info, '^SO  - ')
## DOI
lid<-i[str_detect(i, "^LID ")]
lid<-str_remove_all(lid, '^LID - ')
if (length(lid)>0){
if (str_detect(lid, "doi")){
lid<-str_remove_all(lid, ' .+')
lid<-paste0("https://doi.org/", lid)
}else{
lid<-NULL
}
}else{
lid<-NULL
}
## join all info in dataframe
extract[[p]]<-data.frame("Year" = ifelse(is_empty(year), "No year", year),
"Title" = ifelse(is_empty(title), "No title", title),
"Authors" = ifelse(is_empty(author_names),
"No names", author_names),
"Info" = ifelse(is_empty(pub_info), "No info", pub_info),
"PMID" = ifelse(is_empty(PMID), "No PMID", PMID),
"DOI" = ifelse(is_empty(lid), "No DOI", lid))
}
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(Year)
pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df, rownames = NULL)
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(desc(Year))
pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
datatable(pub_df, rownames = NULL)
x
year_list<-list()
years<-sort(unique(pub_df$Year), decreasing = T)
for (i in 1:length(years)){
year<-years[i]
temp_df<-pub_df[pub_df$Year==year,]
## papers per year
temp_tags<-apply(temp_df, 1, function(x){
list(
tags$h4(
(if (!is.na(x[5])) {
tags$a(href = x[6],x[2],target="_blank")
}else{
tags$a(x[2],target="_blank")
})),
tags$p(x[3],x[4])
)
})
year_list[[i]]<-
tags$div(class = year,
tags$h2(year),
temp_tags
)
}
x<-tags$div(class="top",
year_list)
x
# write.table(htmltools::renderTags(x)$html, file = "test.txt", quote = F, row.names = F)
year_list
year_list<-list()
years<-sort(unique(pub_df$Year), decreasing = T)
for (i in 1:length(years)){
year<-years[i]
temp_df<-pub_df[pub_df$Year==year,]
## papers per year
temp_tags<-apply(temp_df, 1, function(x){
list(
tags$h4(
(if (!is.na(x[5])) {
tags$a(href = x[6],x[2],target="_blank")
}else{
tags$a(x[2],target="_blank")
})),
tags$p(x[3],x[4])
)
})
# year_list[[i]]<-
#   tags$div(class = year,
tags$h2(year)
temp_tags
}
# x<-tags$div(class="top",
#            year_list)
#
# x
# write.table(htmltools::renderTags(x)$html, file = "test.txt", quote = F, row.names = F)
# year_list[[i]]<-
#   tags$div(class = year,
print(tags$h2(year))
print(temp_tags)
# year_list[[i]]<-
#   tags$div(class = year,
htmltools::renderTags(tags$h2(year))
htmltools::renderTags(temp_tags)
# year_list[[i]]<-
#   tags$div(class = year,
cat(tags$h2(year))
year_list<-list()
years<-sort(unique(pub_df$Year), decreasing = T)
for (i in 1:length(years)){
year<-years[i]
temp_df<-pub_df[pub_df$Year==year,]
## papers per year
temp_tags<-apply(temp_df, 1, function(x){
list(
tags$h4(
(if (!is.na(x[5])) {
tags$a(href = x[6],x[2],target="_blank")
}else{
tags$a(x[2],target="_blank")
})),
tags$p(x[3],x[4])
)
})
year_list[[tags$h2(year)]]<-temp_tags
}
year_list[[tags$h2(year)]]<-temp_tags
year_list<-list()
years<-sort(unique(pub_df$Year), decreasing = T)
for (i in 1:length(years)){
year<-years[i]
temp_df<-pub_df[pub_df$Year==year,]
## papers per year
temp_tags<-apply(temp_df, 1, function(x){
list(
tags$h4(
(if (!is.na(x[5])) {
tags$a(href = x[6],x[2],target="_blank")
}else{
tags$a(x[2],target="_blank")
})),
tags$p(x[3],x[4])
)
})
year_list[[i]]<-list(tags$h2(year),temp_tags)
}
x<-tags$div(class="top",
year_list)
x
# write.table(htmltools::renderTags(x)$html, file = "test.txt", quote = F, row.names = F)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df, rownames = NULL)
pub_df$Title<-tags$a(href = pub_df$Link,pub_df$Title,target="_blank")
tags$a(href = pub_df$Link,pub_df$Title,target="_blank")
pub_df$Link
##link
link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", PMID)
title<-tags$a(href = link,title,target="_blank")
title
pub_df<-pub_df%>%select(-DOI)
library(easyPubMed) #API connection with pubmed
library(tidyverse) #To facilitate some data wrangling
library(DT) # for table html formatting
library(htmltools)
## This creates a search that gets saved in NML servers with specific ids, that makes the query reusable without the need to search again.
my_entrez_id <- get_pubmed_ids('Abel Torres-Espin')
## This fetches the pubmed info for each paper returned as list of string character vector
track_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
## Creates an index of where the papers start in the track_txt string
paper_list_index<-c(which(track_txt==""),length(track_txt))
## Extract papers by list
paper_list<-list()
for(i in 1:(length(paper_list_index)-1)){
paper_list[[i]]<-track_txt[seq(paper_list_index[i],paper_list_index[i+1]-1)]
}
## List of PMIDs using the PMID tag
PMC_list<-track_txt[str_detect(track_txt, "^PMID- ")]
PMC_list<-unique(str_remove_all(PMC_list, '^PMID- '))
### build the dataframe
extract<-list()
for (p in 1:length(paper_list)){
i<-paper_list[[p]]
## Author names
author_names<-i[str_detect(i, "^AU ")]
author_names<-paste0(str_remove_all(author_names, "^AU  - "), collapse="; ")
## PMIDs
PMID<-i[str_detect(i, "^PMID- ")]
PMID<-str_remove_all(PMID, '^PMID- ')
## Date publication
date_p<-i[str_detect(i, "^DP ")]
date_p<-str_remove_all(date_p, '^DP  - ')
## year
year<-str_extract(date_p,"[[:digit:]]+")
## Title
title<-i[str_detect(i, "^TI ")]
title<-str_remove_all(title, '^TI  - ')
## Publication info
pub_info<-i[str_detect(i, "^SO ")]
pub_info<-str_remove_all(pub_info, '^SO  - ')
## DOI
lid<-i[str_detect(i, "^LID ")]
lid<-str_remove_all(lid, '^LID - ')
if (length(lid)>0){
if (str_detect(lid, "doi")){
lid<-str_remove_all(lid, ' .+')
lid<-paste0("https://doi.org/", lid)
}else{
lid<-NULL
}
}else{
lid<-NULL
}
##link
link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", PMID)
title<-tags$a(href = link,title,target="_blank")
## join all info in dataframe
extract[[p]]<-data.frame("Year" = ifelse(is_empty(year), "No year", year),
"Title" = ifelse(is_empty(title), "No title", title),
"Authors" = ifelse(is_empty(author_names),
"No names", author_names),
"Info" = ifelse(is_empty(pub_info), "No info", pub_info),
"PMID" = ifelse(is_empty(PMID), "No PMID", PMID),
"DOI" = ifelse(is_empty(lid), "No DOI", lid))
}
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(desc(Year))
# pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df, rownames = NULL, escape = 2,
options = list(
autoWidth = TRUE, columnDefs = list(list(width = '200px', targets = c(1, 3))))
)
View(pub_df)
title<-tags$a(href = link,title,target="_blank")
View(title)
title<-print(tags$a(href = link,title,target="_blank"))
print(tags$a(href = link,title,target="_blank"))
library(easyPubMed) #API connection with pubmed
library(tidyverse) #To facilitate some data wrangling
library(DT) # for table html formatting
library(htmltools)
## This creates a search that gets saved in NML servers with specific ids, that makes the query reusable without the need to search again.
my_entrez_id <- get_pubmed_ids('Abel Torres-Espin')
## This fetches the pubmed info for each paper returned as list of string character vector
track_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
## Creates an index of where the papers start in the track_txt string
paper_list_index<-c(which(track_txt==""),length(track_txt))
## Extract papers by list
paper_list<-list()
for(i in 1:(length(paper_list_index)-1)){
paper_list[[i]]<-track_txt[seq(paper_list_index[i],paper_list_index[i+1]-1)]
}
## List of PMIDs using the PMID tag
PMC_list<-track_txt[str_detect(track_txt, "^PMID- ")]
PMC_list<-unique(str_remove_all(PMC_list, '^PMID- '))
### build the dataframe
extract<-list()
for (p in 1:length(paper_list)){
i<-paper_list[[p]]
## Author names
author_names<-i[str_detect(i, "^AU ")]
author_names<-paste0(str_remove_all(author_names, "^AU  - "), collapse="; ")
## PMIDs
PMID<-i[str_detect(i, "^PMID- ")]
PMID<-str_remove_all(PMID, '^PMID- ')
## Date publication
date_p<-i[str_detect(i, "^DP ")]
date_p<-str_remove_all(date_p, '^DP  - ')
## year
year<-str_extract(date_p,"[[:digit:]]+")
## Title
title<-i[str_detect(i, "^TI ")]
title<-str_remove_all(title, '^TI  - ')
## Publication info
pub_info<-i[str_detect(i, "^SO ")]
pub_info<-str_remove_all(pub_info, '^SO  - ')
## DOI
lid<-i[str_detect(i, "^LID ")]
lid<-str_remove_all(lid, '^LID - ')
if (length(lid)>0){
if (str_detect(lid, "doi")){
lid<-str_remove_all(lid, ' .+')
lid<-paste0("https://doi.org/", lid)
}else{
lid<-NULL
}
}else{
lid<-NULL
}
##link
link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", PMID)
title<-print(tags$a(href = link,title,target="_blank"))
## join all info in dataframe
extract[[p]]<-data.frame("Year" = ifelse(is_empty(year), "No year", year),
"Title" = ifelse(is_empty(title), "No title", title),
"Authors" = ifelse(is_empty(author_names),
"No names", author_names),
"Info" = ifelse(is_empty(pub_info), "No info", pub_info),
"PMID" = ifelse(is_empty(PMID), "No PMID", PMID),
"DOI" = ifelse(is_empty(lid), "No DOI", lid))
}
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(desc(Year))
# pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
title<-htmltools::a(href = link,title,target="_blank")
title
View(title)
title<-htmltools::renderTags(tags$a(href = link,title,target="_blank"))
View(title)
library(easyPubMed) #API connection with pubmed
library(tidyverse) #To facilitate some data wrangling
library(DT) # for table html formatting
library(htmltools)
## This creates a search that gets saved in NML servers with specific ids, that makes the query reusable without the need to search again.
my_entrez_id <- get_pubmed_ids('Abel Torres-Espin')
## This fetches the pubmed info for each paper returned as list of string character vector
track_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
## Creates an index of where the papers start in the track_txt string
paper_list_index<-c(which(track_txt==""),length(track_txt))
## Extract papers by list
paper_list<-list()
for(i in 1:(length(paper_list_index)-1)){
paper_list[[i]]<-track_txt[seq(paper_list_index[i],paper_list_index[i+1]-1)]
}
## List of PMIDs using the PMID tag
PMC_list<-track_txt[str_detect(track_txt, "^PMID- ")]
PMC_list<-unique(str_remove_all(PMC_list, '^PMID- '))
### build the dataframe
extract<-list()
for (p in 1:length(paper_list)){
i<-paper_list[[p]]
## Author names
author_names<-i[str_detect(i, "^AU ")]
author_names<-paste0(str_remove_all(author_names, "^AU  - "), collapse="; ")
## PMIDs
PMID<-i[str_detect(i, "^PMID- ")]
PMID<-str_remove_all(PMID, '^PMID- ')
## Date publication
date_p<-i[str_detect(i, "^DP ")]
date_p<-str_remove_all(date_p, '^DP  - ')
## year
year<-str_extract(date_p,"[[:digit:]]+")
## Title
title<-i[str_detect(i, "^TI ")]
title<-str_remove_all(title, '^TI  - ')
## Publication info
pub_info<-i[str_detect(i, "^SO ")]
pub_info<-str_remove_all(pub_info, '^SO  - ')
## DOI
lid<-i[str_detect(i, "^LID ")]
lid<-str_remove_all(lid, '^LID - ')
if (length(lid)>0){
if (str_detect(lid, "doi")){
lid<-str_remove_all(lid, ' .+')
lid<-paste0("https://doi.org/", lid)
}else{
lid<-NULL
}
}else{
lid<-NULL
}
##link
link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", PMID)
title<-htmltools::renderTags(tags$a(href = link,title,target="_blank"))$html
## join all info in dataframe
extract[[p]]<-data.frame("Year" = ifelse(is_empty(year), "No year", year),
"Title" = ifelse(is_empty(title), "No title", title),
"Authors" = ifelse(is_empty(author_names),
"No names", author_names),
"Info" = ifelse(is_empty(pub_info), "No info", pub_info),
"PMID" = ifelse(is_empty(PMID), "No PMID", PMID),
"DOI" = ifelse(is_empty(lid), "No DOI", lid))
}
## Create the dataframe
pub_df<-do.call(rbind, extract)
pub_df<-pub_df%>%arrange(desc(Year))
# pub_df$Link<-paste0("https://pubmed.ncbi.nlm.nih.gov/", pub_df$PMID)
pub_df<-pub_df%>%select(-DOI)
datatable(pub_df, rownames = NULL, escape = 2,
options = list(
autoWidth = TRUE, columnDefs = list(list(width = '200px', targets = c(1, 3))))
)
distill::create_post()
distill::create_post("From wet lab to data science")
create_post("Collaboration Network", draft = TRUE)
distill::create_post("Collaboration Network", draft = TRUE)
distill::create_post("Reproducing Schotter in R", draft = TRUE)
knitr::opts_chunk$set(echo = FALSE)
library(easyPubMed) #API connection with pubmed
knitr::opts_chunk$set(echo = FALSE)
library(easyPubMed) #API connection with pubmed
library(tidyverse) #To facilitate some data wrangling
library(igraph) #To build the graph
library(visNetwork) #Interactive networks
my_entrez_id <- get_pubmed_ids('Torres-Espin A')
my_author_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
authors<-my_author_txt[str_detect(my_author_txt, "^AU ")]
coauthors_list<-unique(str_remove_all(authors, '^AU  - '))
head(coauthors_list)
author_list<-list()#define the list to save the data frames
for (i in 1:length(coauthors_list)){
my_entrez_id <- get_pubmed_ids(coauthors_list[i])
my_author_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
authors<-my_author_txt[str_detect(my_author_txt, "^AU ")]
authors<-str_remove_all(authors, '^AU  - ')
author_list[[i]]<-data.frame(co_authors=authors, author=coauthors_list[i])
}
my_entrez_id
my_author_txt
authors
authors
my_author_txt
coauthors_list[i]
my_entrez_id
my_author_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
i<-42
my_entrez_id <- get_pubmed_ids(coauthors_list[i])
my_entrez_id
my_author_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
my_author_txt
for (i in 41:length(coauthors_list)){
my_entrez_id <- get_pubmed_ids(coauthors_list[i])
my_author_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
if (is.null(my_author_txt)) next()
authors<-my_author_txt[str_detect(my_author_txt, "^AU ")]
authors<-str_remove_all(authors, '^AU  - ')
author_list[[i]]<-data.frame(co_authors=authors, author=coauthors_list[i])
}
my_author_txt
length(my_author_txt)==0
for (i in 42:length(coauthors_list)){
my_entrez_id <- get_pubmed_ids(coauthors_list[i])
my_author_txt <- fetch_pubmed_data(my_entrez_id, format = "medline")
if (length(my_author_txt)==0) next()
authors<-my_author_txt[str_detect(my_author_txt, "^AU ")]
authors<-str_remove_all(authors, '^AU  - ')
author_list[[i]]<-data.frame(co_authors=authors, author=coauthors_list[i])
}
author_df<-do.call(rbind, author_list)#stack data frames
author_df<-author_df[author_df$co_authors%in%author_df$author,]%>%
mutate(co_edge=paste(co_authors, author, sep = '_'))%>%
group_by(co_edge)%>%
summarise(count=n())%>%
separate(co_edge, c('co_authors','author'),sep = '_')
author_g<-graph_from_data_frame(author_df,directed = F)
E(author_g)$weight<-author_df$count
author_g<-simplify(author_g)
plot(author_g,edge.width = E(author_g)$weight)
vis_g<-toVisNetworkData(author_g) #coverts the igraph object to visNetwork
vis_g$edges$value<-vis_g$edges$weight #specify the values for eadges as the weights (number of papers for pairs)
#vis_g$nodes$title<-co_authors_abel$author_name #name of the nodes
#plot the network
visNetwork(nodes = vis_g$nodes, edges = vis_g$edges, height = "300px", width = '300px')%>%
visNodes(size = 10, shape='cicle', mass=2,font=list(color='white'),fixed = F) %>%
visEdges(length = 10,physics = T, smooth = list(enabled=T))%>%
visLayout(randomSeed = 666)%>%
visOptions(highlightNearest = list(hover = T),
nodesIdSelection = list(enabled = TRUE))%>%
visPhysics(stabilization = T, minVelocity = 10, maxVelocity = 25)
